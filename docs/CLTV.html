<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Swapnil" />


<title>Customer Lifetime Value Modeling</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Portfolio</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="About.html">About</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Customer Lifetime Value Modeling</h1>
<h4 class="author">Swapnil</h4>
<h4 class="date">8/19/2019</h4>

</div>


<div id="introduction" class="section level3">
<h3>Introduction</h3>
<p>This project is aimed at comaparing various CLTV models and their prediction accuracy. Most of the models around CLTV are based on Pareto/NBD model which was proposed by <strong>Schmittlein</strong>. In 2003 <strong>Peter S Fader</strong> expanded upon this model and introduced <em>BG/NBD</em> model as an alternative to Pareto/NBD. The new model is computationally light and has similar accuracy as the base model. The paper can be found <strong><a href="http://www.brucehardie.com/papers/bgnbd_2004-04-20.pdf">here</a></strong></p>
<p><strong>Michael Platzer</strong> in 2014 released R package called <strong><a href="https://cran.r-project.org/web/packages/BTYDplus/vignettes/BTYDplus-HowTo.pdf">BTYDPlus</a></strong> which included few more models for CLTV calculations.</p>
<p>Following models are discussed-</p>
<p><strong>MLE based models-</strong> These are the models in which parameter estimation happens based on maximum likelihood</p>
<ul>
<li>NBD</li>
<li>PNBD</li>
<li>MBG/NBD</li>
<li>BG/CNBD-k</li>
<li>MBG/CNBD-k</li>
</ul>
<p><strong>Markov-Chain-Monte-Carlo based models-</strong> These models use MCMC simulation for parameter estimation</p>
<ul>
<li>Pareto/NBD</li>
<li>Pareto/GGG</li>
</ul>
</div>
<div id="assumptions" class="section level3">
<h3>Assumptions</h3>
<p>Almost all CLTV models are based on following major assumptions-</p>
<ul>
<li><strong>Assumption 1:</strong> number of transactions made by any active customer follows a Poisson Process with transaction rate λ</li>
<li><strong>Assumption 2:</strong> Different customers have different purchase rate, thus, heterogeneity in transaction rates among customers follows a Gamma distribution.</li>
<li><strong>Assumption 3:</strong> A customer can become inactive with probability <em>p</em> after every transaction</li>
<li><strong>Assumption 4:</strong> Probability <em>p</em> of being inactive after each transaction is different for each customer and the heterogeneity in <em>p</em> follows a Beta distribution.</li>
<li><strong>Assumption 5:</strong> the transaction rate λ and the dropout probability p vary independently across customers.</li>
</ul>
</div>
<div id="practical-example" class="section level3">
<h3>Practical Example</h3>
<p>For this, we are using good old <a href="https://archive.ics.uci.edu/ml/datasets/Online%20Retail">online retail</a> data from UCI machine learning repository.</p>
<p>This project is focused on understanding CLTV modeling, so I am skipping over data cleaning and other EDA steps (not challenging your intellect here!)</p>
<p>I cleaned the data and aggregated transactions at order day level. Now we need to see how the transactions are spread over the period so that we can decide calibration and test period. We are going to caliberate on data before Aug-11 and use rest of the data for testing.</p>
<pre class="r"><code>## Now data looks okay.. We need to caste datetime to date for building BYTD model
retail$InvoiceDate&lt;-as.Date(retail$InvoiceDate)
#summary(retail$InvoiceDate)
## cutoff for calibration and testing
cutoffDate&lt;-as.Date(&quot;2011-08-01&quot;)
##caliberatonPeriod Aprox 19 weeks
#(max(retail$InvoiceDate)-cutoffDate)</code></pre>
<pre class="r"><code>## Summarising the entire data

orderDaySummary&lt;-retail%&gt;%
  group_by(CustomerID,InvoiceDate)%&gt;%
  summarise(demand=sum(Quantity*UnitPrice))%&gt;%
  arrange(CustomerID,InvoiceDate)%&gt;%
  data.frame()

customerSummary&lt;-orderDaySummary%&gt;%
  group_by(CustomerID)%&gt;%
  summarise(demand=sum(demand),transactions=n(), birth=min(InvoiceDate),death=max(InvoiceDate),
            period=max(InvoiceDate)-min(InvoiceDate))%&gt;%
  arrange(CustomerID)%&gt;%
  data.frame()


orderDaySummary&lt;-merge(orderDaySummary,customerSummary,by = &#39;CustomerID&#39;)</code></pre>
<p>To help users how customer behaviour looks over the timeline, we will try to visualize customers’ buying frequency. I randomly select some customers and plot their transactions w.r.t. caliberation cutoff.</p>
<pre class="r"><code>### Visualization of sample customers and their journey
set.seed(222)


viZdata&lt;-filter(orderDaySummary,CustomerID&lt;12380)%&gt;%
  data.frame()

#str(viZdata)

ggplot(data = viZdata,aes(x =InvoiceDate,y = CustomerID))+
  geom_point(shape=4,size=2)+geom_segment(aes(x = birth, y = CustomerID, xend = death, yend = CustomerID,col=&#39;Journey&#39;))+
  geom_vline(xintercept = cutoffDate,linetype=&#39;dashed&#39;)+annotate(&quot;text&quot;,x = as.Date(&quot;2011-10-01&quot;),y = 12382, label=&quot;Test Period&quot;)+
  annotate(&quot;text&quot;,x = as.Date(&quot;2011-05-01&quot;),y = 12382, label=&quot;Caliberation Period&quot;)</code></pre>
<p><img src="CLTV_files/figure-html/unnamed-chunk-4-1.png" width="960" /></p>
<p>Now the firt two assumptions of CLTV modeling state that transaction rate of each customer follows Poisson Distribution and the values of transaction rate λ among the cohort follow Gamma distribution. Lets try to simulate this for our data. FOr this, we will first generate list of transaction rates λ using gamma distribution and then gererate transactions using those λ’s. In our data, average transaction rate for the time period is 3.8. Every line in the graph below is one simulated customer and the line is PDF of the customers transactions in given time. As we can see transaction behavior is very different among different customers.</p>
<pre class="r"><code>#summary(customerSummary$transactions)
# average transactions of each customer over the period is 3.8
set.seed(22)
y&lt;-rgamma(n = 100,shape = 3.8,scale = 1)
simData&lt;-data.frame(customers=numeric()
                    ,transactions=numeric())
for(i in 1:length(y))
{
  temp&lt;-rpois(n = 100,lambda = y[i])
  tempDf&lt;-data.frame(cbind(customers=i,transactions=temp))
  simData&lt;-rbind(simData,tempDf)
}
simData$customers&lt;-as.factor(simData$customers)
ggplot(data = simData,aes(x = transactions,fill=customers))+geom_line(stat = &#39;density&#39;,alpha=0.3)+
  ggtitle(&#39;Simulation of probabilities of transactions&#39;)+xlab(&quot;Transactions&quot;)+ylab(&quot;Probability&quot;)</code></pre>
<p><img src="CLTV_files/figure-html/unnamed-chunk-5-1.png" width="960" /></p>
<p>Now we need to convert the data into CBS format-<strong>Customer-by-sufficient-statistic</strong> dataframe. This data frame has following columns-</p>
<ul>
<li>x (frequency) - number of repeat transactions</li>
<li>litt the sum over logarithmic intertransaction times (introduced in BTYDPlus package)</li>
<li>first the date of the first transaction</li>
<li>T.cal the duration between the first transaction and the end of the calibration period</li>
<li>x.star the number of repeat transactions during the holdout period of length T.star</li>
</ul>
<pre class="r"><code>## Default weeks, includes only those who have made atleast one repeat purchase?
interimData&lt;-orderDaySummary[,c(1,2,3)]
names(interimData)&lt;-c(&#39;cust&#39;,&#39;date&#39;,&#39;sales&#39;)
custCbs&lt;-elog2cbs(interimData,T.cal = cutoffDate)
#head(custCbs)</code></pre>
<p>Now we test regularity of transaction times. A return value of close to 1 supports the assumption of exponentially distributed inter transaction times, whereas values significantly larger than 1 reveal the presence of regularity. Since both values are above 1, it represents regularity in transactions</p>
<pre class="r"><code>mfrow = c(1, 2)
a&lt;-estimateRegularity(groceryElog, method = &quot;wheat&quot;,
                               plot = TRUE, title = &quot;Wheat &amp; Morrison&quot;)</code></pre>
<p><img src="CLTV_files/figure-html/unnamed-chunk-7-1.png" width="960" /></p>
<pre class="r"><code>b&lt;-estimateRegularity(groceryElog, method = &quot;mle&quot;,
                             plot = TRUE, title = &quot;Maximum Likelihood&quot;)</code></pre>
<p><img src="CLTV_files/figure-html/unnamed-chunk-7-2.png" width="960" /></p>
<pre class="r"><code>c(a,b)</code></pre>
<pre><code>## [1] 1.826974 3.262912</code></pre>
</div>
<div id="parameter-estimation-of-mle-based-models-" class="section level3">
<h3>Parameter estimation of MLE based models-</h3>
<pre class="r"><code>#estimate parameters for various models
set.seed(1234)
params.nbd &lt;- nbd.EstimateParameters(custCbs) # NBD
params.bgnbd &lt;- BTYD::bgnbd.EstimateParameters(custCbs) # BG/NBD
params.bgcnbd &lt;- bgcnbd.EstimateParameters(custCbs) # BG/CNBD-k
params.mbgnbd &lt;- mbgnbd.EstimateParameters(custCbs) # MBG/NBD
params.mbgcnbd &lt;- mbgcnbd.EstimateParameters(custCbs) # MBG/CNBD-k
## log likelihood of all models
rbind(c(&quot;NBD&quot;, nbd.cbs.LL(params.nbd, custCbs)),
      c(&quot;BG/NBD&quot;, BTYD::bgnbd.cbs.LL(params.bgnbd, custCbs)),
      c(&quot;BG/CNBD-k&quot;, bgcnbd.cbs.LL(params.bgcnbd, custCbs)),
      c(&quot;MBG/NBD&quot;, mbgcnbd.cbs.LL(params.mbgnbd, custCbs)),
      c(&quot;MBG/CNBD-k&quot;, mbgcnbd.cbs.LL(params.mbgcnbd, custCbs)))%&gt;%
  data.frame()</code></pre>
<pre><code>##           X1                X2
## 1        NBD -21704.5285173858
## 2     BG/NBD -21678.5834988302
## 3  BG/CNBD-k -21678.5834988302
## 4    MBG/NBD -21690.0786754486
## 5 MBG/CNBD-k -21690.0786754486</code></pre>
<p>Log Likelihoodh helps us identify model that performs the best. We will test for other models too.</p>
</div>
<div id="parameter-estimation-of-mcmc-based-models-" class="section level3">
<h3>Parameter estimation of MCMC based models-</h3>
<pre class="r"><code>##### Pareto/NBD hb
pnbd.draws &lt;- pnbd.mcmc.DrawParameters(custCbs)</code></pre>
<pre><code>## set param_init: 0.8116, 7.5903, 0.0238, 1.2482 
## running in parallel on 2 cores</code></pre>
<pre class="r"><code>pnbd.xstar.draws &lt;- mcmc.DrawFutureTransactions(custCbs, pnbd.draws)

### Pareto/GGG
pggg.draws &lt;- pggg.mcmc.DrawParameters(custCbs) </code></pre>
<pre><code>## set param_init: 1, 1, 0.8783, 7.7295, 0.0178, 0.4024 
## running in parallel on 2 cores</code></pre>
<pre class="r"><code>pggg.xstar.draws &lt;- mcmc.DrawFutureTransactions(custCbs, pggg.draws)</code></pre>
</div>
<div id="cohort-level-predictions" class="section level3">
<h3>Cohort level predictions</h3>
<p>These models are usually not good for customer lever predictions.</p>
<pre class="r"><code># NBD
custCbs$xstar.nbd &lt;- nbd.ConditionalExpectedTransactions(
  params = params.nbd, T.star = 19,
  x = custCbs$x, 
  T.cal = custCbs$T.cal)
#BG/NBD
custCbs$xstar.bgnbd&lt;- BTYD::bgnbd.ConditionalExpectedTransactions(
  params = params.bgnbd , T.star = 19,
  x = custCbs$x, t.x = custCbs$t.x,
  T.cal = custCbs$T.cal)
#BG/CNBD-k
custCbs$xstar.bgcnbd&lt;- bgcnbd.ConditionalExpectedTransactions(
  params = params.bgcnbd , T.star = 19,
  x = custCbs$x, t.x = custCbs$t.x,
  T.cal = custCbs$T.cal)
#MBG/NBD
custCbs$xstar.mbgnbd&lt;- bgcnbd.ConditionalExpectedTransactions(
  params = params.mbgnbd , T.star = 19,
  x = custCbs$x, t.x = custCbs$t.x,
  T.cal = custCbs$T.cal)
# MBG/CNBD-k
custCbs$xstar.mbgcnbd&lt;- mbgcnbd.ConditionalExpectedTransactions(
  params = params.mbgcnbd , T.star = 19,
  x = custCbs$x, t.x = custCbs$t.x,
  T.cal = custCbs$T.cal)
##### Pareto/NBD hb
custCbs$xstar.pnbd.hb &lt;- apply(pnbd.xstar.draws, 2, mean)
### Pareto/GGG
custCbs$xstar.pggg &lt;- apply(pggg.xstar.draws, 2, mean)


# compare predictions with actuals at aggregated level
comps&lt;-rbind(`Acutuals` = c(`Acutal` = sum(custCbs$x.star)),
             `NBD` = round(sum(custCbs$xstar.nbd)),
             `BG/NBD` = round(sum(custCbs$xstar.bgnbd)),
             `BG/CNBD-k` = round(sum(custCbs$xstar.bgcnbd)),
             `MBG/NBD`= round(sum(custCbs$xstar.mbgnbd)),
             `MBG/CNBD-k` = round(sum(custCbs$xstar.mbgcnbd)),
             
             
             `Pareto/NBD hb` = round(sum(custCbs$xstar.pnbd.hb)),
             `Pareto/GGG` = round(sum(custCbs$xstar.pggg)))%&gt;%
  data.frame()
ggplot(data =comps ,aes(y = Acutal,x = reorder(rownames(comps),Acutal)))+geom_col()+ggtitle(&#39;Cohort level prediction comparison&#39;)+
  ylab(&#39;Transactions&#39;)+xlab(&#39;Model Name&#39;)+coord_flip()</code></pre>
<p><img src="CLTV_files/figure-html/unnamed-chunk-10-1.png" width="960" /></p>
<pre class="r"><code>absoluteError&lt;-function(actual,predicted)
{
  return(sum(abs(actual-predicted))/sum(actual))
}

comps&lt;-rbind(`NBD` = absoluteError(custCbs$x.star,custCbs$xstar.nbd),
             `BG/NBD` = absoluteError(custCbs$x.star,custCbs$xstar.bgnbd),
             `BG/CNBD-k` = absoluteError(custCbs$x.star,custCbs$xstar.bgcnbd),
             `MBG/NBD`= absoluteError(custCbs$x.star,custCbs$xstar.mbgnbd),
             `MBG/CNBD-k` = absoluteError(custCbs$x.star,custCbs$xstar.mbgcnbd),
             `Pareto/NBD hb` = absoluteError(custCbs$x.star,custCbs$xstar.pnbd.hb),
             `Pareto/GGG` = absoluteError(custCbs$x.star,custCbs$xstar.pggg))%&gt;%
  data.frame()
colnames(comps)&lt;-&quot;AbsoluteError&quot;
comps</code></pre>
<pre><code>##               AbsoluteError
## NBD               0.6578187
## BG/NBD            0.6482107
## BG/CNBD-k         0.6482107
## MBG/NBD           0.6523493
## MBG/CNBD-k        0.6519190
## Pareto/NBD hb     0.6553530
## Pareto/GGG        0.6510682</code></pre>
<p>This is not the best cohort level prediction but we can plat around with different caliberation/test period windows and increasing customer count.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
